{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from ast import literal_eval\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from yt_rag.agent import llm, build_prompt\n",
    "from yt_rag.build_index import build_index, create_embeddings, embed_title\n",
    "from yt_info.yt_video_data import Video, get_video_transcript\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OLLAMA_URL = os.getenv(\"LOCAL_OLLAMA_URL\")\n",
    "CHANNELS = literal_eval(os.getenv(\"YT_CHANNELS\"))\n",
    "ES_URL = os.getenv(\"LOCAL_ES_URL\")\n",
    "ES_INDEX_NAME = os.getenv(\"ES_INDEX_NAME\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "ollama_client = OpenAI(base_url=OLLAMA_URL, api_key=\"ollama\")\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "embedding_model = SentenceTransformer(\"multi-qa-distilbert-cos-v1\")\n",
    "\n",
    "es_client = Elasticsearch(ES_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/yt_videos_details.pkl', 'rb') as f:\n",
    "    videos = pickle.load(f)\n",
    "\n",
    "\n",
    "# change to results_tempDefault.pkl to use the LLM generated questions with the default temperature.\n",
    "with open('../data/results_temp0.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_llm = \"\"\"\n",
    "You are a user of a cooking and recipe assistant app.\n",
    "Generate 5 general questions related to the cooking techniques, ingredients, or recipes discussed in the provided video.\n",
    "The questions should be clear, concise, and relevant to the video's content.\n",
    "Avoid being overly specific about particular ingredients or using too many details from the title and description.\n",
    "Do not mention or reference the video title, description, or any URLs.\n",
    "Focus on broader cooking themes that would be of interest to a home cook.\n",
    "\n",
    "The video information:\n",
    "\n",
    "title: {title}\n",
    "description: {description}\n",
    "\n",
    "Output the result as a JSON object without using code blocks:\n",
    "\n",
    "{{\"questions\": [\"question1\", \"question2\", \"question3\", \"question4\", \"question5\"]}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(video):\n",
    "    prompt = prompt_llm.format(**video.__dict__)\n",
    "\n",
    "    response = llm(prompt, client=ollama_client)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "failed_video_ids = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in tqdm(videos): \n",
    "    if video.video_id in results:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        questions_raw = generate_questions(video)\n",
    "    except Exception as err:\n",
    "        print(f\"Failed {video.video_id}\", err)\n",
    "        continue\n",
    "\n",
    "\n",
    "    try:\n",
    "        questions = json.loads(questions_raw.replace(\"json\", \"\").replace(\"`\", \"\").strip())\n",
    "    except json.JSONDecodeError:\n",
    "        # print(f\"JSON fail for {video.video_id}\")\n",
    "        failed_video_ids[video.video_id] = questions_raw\n",
    "        continue        \n",
    "    except Exception as err:\n",
    "        # print(f\"Failed {video.video_id}\", err)\n",
    "        failed_video_ids[video.video_id] = questions_raw\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            results[video.video_id] = questions['questions']\n",
    "        except KeyError:\n",
    "            failed_video_ids[video.video_id] = questions_raw\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_text(query):\n",
    "    search_query = {\n",
    "        \"_source\": [\"title\", \"is_short\", \"description\", \"video_id\"],\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"title\", \"description\"],\n",
    "                        \"type\": \"best_fields\",\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=ES_INDEX_NAME, body=search_query)\n",
    "    return [hit[\"_source\"] for hit in response[\"hits\"][\"hits\"]]\n",
    "\n",
    "\n",
    "def elastic_search_knn(query, index=ES_INDEX_NAME, field=\"title_description_vector\"):\n",
    "        \n",
    "    vector = embedding_model.encode(query)\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"title\", \"is_short\", \"description\", \"course\", \"video_id\"],\n",
    "    }\n",
    "    es_results = es_client.search(index=index, body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in es_results[\"hits\"][\"hits\"]:\n",
    "        result_docs.append(hit[\"_source\"])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['video_id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [{\"id\": k, \"question\": _v} for k, v in results.items() for _v in v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector+KNN search CONCAT(Title + description) with Phi3-Mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = create_embeddings(videos)\n",
    "build_index(videos, embeddings, ES_INDEX_NAME, es_client=es_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text search on Title and description with Phi3-Mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_text(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector+KNN search on Title with Phi3-Mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_only_index_name = ES_INDEX_NAME+\"-title-only\"\n",
    "embeddings = create_embeddings(videos, embedding_function=embed_title)\n",
    "build_index(videos, embeddings, title_only_index_name, es_client=es_client, field=\"title_vector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], index=title_only_index_name, field=\"title_vector\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_rag_eval = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template1 = \"\"\"\n",
    "You are a professional cook and recipe developer. Answer the QUESTION using only the information provided in the CONTEXT from the video transcript.\n",
    "Do not include any information, assumptions, or details not present in the CONTEXT. If the CONTEXT does not provide enough information to answer the QUESTION, acknowledge the limitation.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_template2 = \"\"\"\n",
    "You are a professional cook and recipe developer. Your task is to answer the QUESTION based only on the information provided in the CONTEXT from the video transcript.\n",
    "\n",
    "Please follow these guidelines:\n",
    "- Provide a clear and concise answer directly related to the QUESTION.\n",
    "- Avoid any conversational elements or references to the video format (such as \"welcome back\" or \"subscribe\").\n",
    "- Do not introduce information, assumptions, or details that are not present in the CONTEXT.\n",
    "- If the CONTEXT does not provide enough information to fully answer the QUESTION, acknowledge this and explain the limitation.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "def get_answer(query, prompt_template):\n",
    "    es_videos = elastic_search_knn(query)\n",
    "    es_videos = [Video(**video) for video in es_videos]\n",
    "    transcripts = []\n",
    "    for video in es_videos[:1]:\n",
    "        transcript = get_video_transcript(video)\n",
    "        transcripts.append(\"\\n\".join([line[\"text\"] for line in transcript]))\n",
    "\n",
    "    prompt = build_prompt(query, es_videos[:1], transcripts, prompt_template=prompt_template)\n",
    "    answer = llm(prompt, model_choice=\"ollama/phi3:mini\")\n",
    "    \n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.sample(ground_truth, 100)\n",
    "rag_evals_template_1 = []\n",
    "rag_evals_template_2 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in tqdm(sample[7:]):\n",
    "    question = entry[\"question\"]\n",
    "    \n",
    "    llm_answer_template1 = get_answer(question, prompt_template1)\n",
    "    llm_answer_template2 = get_answer(question, prompt_template2)\n",
    "    \n",
    "    rag_eval_prompt_template1 = prompt_rag_eval.format(question=question, answer_llm=llm_answer_template1)   \n",
    "    rag_eval_prompt_template2 = prompt_rag_eval.format(question=question, answer_llm=llm_answer_template2)   \n",
    "\n",
    "    rag_llm_eval_template1 = llm(rag_eval_prompt_template1, model_choice=\"openai/gpt-4o-mini\")\n",
    "    rag_llm_eval_template2 = llm(rag_eval_prompt_template2, model_choice=\"openai/gpt-4o-mini\")\n",
    "    \n",
    "    rag_evals_template_1.append((entry, rag_llm_eval_template1))\n",
    "    rag_evals_template_2.append((entry, rag_llm_eval_template2))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42097c99d85c3de64a416612e20e99fe9f8b2589256f2e83a2a3abfd51f5773a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 ('yt-summaries-019raoQi-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
