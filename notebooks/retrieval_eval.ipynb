{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro-loka/.cache/pypoetry/virtualenvs/yt-summaries-019raoQi-py3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/pedro-loka/.cache/pypoetry/virtualenvs/yt-summaries-019raoQi-py3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from ast import literal_eval\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from yt_rag.agent import llm\n",
    "from yt_rag.build_index import build_index, create_embeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OLLAMA_URL = os.getenv(\"LOCAL_OLLAMA_URL\")\n",
    "CHANNELS = literal_eval(os.getenv(\"YT_CHANNELS\"))\n",
    "YT_API_KEY = os.getenv(\"YT_API_KEY\")\n",
    "LOCAL_YT_API_KEY = os.getenv(\"LOCAL_YT_API_KEY\")\n",
    "LOCAL_ES_URL = os.getenv(\"LOCAL_ES_URL\")\n",
    "LOCAL_ES_INDEX_NAME = os.getenv(\"ES_INDEX_NAME\")\n",
    "\n",
    "ollama_client = OpenAI(base_url=OLLAMA_URL, api_key=\"ollama\")\n",
    "embedding_model = SentenceTransformer(\"multi-qa-distilbert-cos-v1\")\n",
    "\n",
    "es_client = Elasticsearch(LOCAL_ES_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/videos.pkl', 'rb') as f:\n",
    "    videos = pickle.load(f)\n",
    "\n",
    "\n",
    "with open('../data/results.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate a user of our cooking and recipe assistant application.\n",
    "Formulate 5 questions this user might ask that would be answered by the provided video.\n",
    "Make the questions specific to this video, without mentioning the video title or description.\n",
    "Avoid references similar to \"to this video\", \"shown here\", \"the shared\". \n",
    "Ignore product links and other urls.\n",
    "Focus on ingredients, techniques or other kitchen related jargon.\n",
    "The record should contain the answer to the questions, and the questions should\n",
    "be complete and not too short. Use as fewer words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "title: {title}\n",
    "description: {description}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "{{\"questions\": [\"question1\", \"question2\", ..., \"question5\"]}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(video):\n",
    "    prompt = prompt_template.format(**video.__dict__)\n",
    "\n",
    "    response = llm(prompt, client=ollama_client)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "failed_video_ids = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in tqdm([i for i in videos if i.video_id in failed_video_ids]): \n",
    "    if video.video_id in results or video.video_id in results:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        questions_raw = generate_questions(video)\n",
    "    except Exception as err:\n",
    "        print(f\"Failed {video.video_id}\", err)\n",
    "        continue\n",
    "\n",
    "\n",
    "    try:\n",
    "        questions = json.loads(questions_raw.replace(\"json\", \"\").replace(\"`\", \"\").strip())\n",
    "    except json.JSONDecodeError:\n",
    "        # print(f\"JSON fail for {video.video_id}\")\n",
    "        failed_video_ids[video.video_id] = questions_raw\n",
    "        continue        \n",
    "    except Exception as err:\n",
    "        # print(f\"Failed {video.video_id}\", err)\n",
    "        failed_video_ids[video.video_id] = questions_raw\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            results[video.video_id] = questions['questions']\n",
    "        except KeyError:\n",
    "            failed_video_ids[video.video_id] = questions_raw\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Evalutaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(query):\n",
    "    field = \"title_description_vector\"\n",
    "    \n",
    "    vector = embedding_model.encode(query)\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 20,\n",
    "        \"num_candidates\": 10000,\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"title\", \"is_short\", \"description\", \"course\", \"video_id\"],\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(index=LOCAL_ES_INDEX_NAME, body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in es_results[\"hits\"][\"hits\"]:\n",
    "        result_docs.append(hit[\"_source\"])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['video_id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [{\"id\": k, \"question\": _v} for k, v in results.items() for _v in v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title + description and Phi3-Mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting embedding...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7f35f7fca5494b870d61175c9a5a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...embedding done.\n",
      "Started indexing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6234d3c40fc341599e97d9000275141e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...indexing done.\n"
     ]
    }
   ],
   "source": [
    "embeddings = create_embeddings(videos)\n",
    "build_index(videos, embeddings, LOCAL_ES_INDEX_NAME, es_client=es_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2041/2041 [02:12<00:00, 15.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6947574718275356, 'mrr': 0.5127479915696481}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question']))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42097c99d85c3de64a416612e20e99fe9f8b2589256f2e83a2a3abfd51f5773a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 ('yt-summaries-019raoQi-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
